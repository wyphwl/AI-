from langchain.memory import ConversationBufferMemory, ConversationBufferWindowMemory, ConversationSummaryMemory, \
    ConversationSummaryBufferMemory
import streamlit as st
import pandas as pd
from ultil import get_chat_response

st.title("ğŸ’—å°å¦²å·±ğŸ’—")


def set_api_key():
    api_key = st.text_input("è¯·è¾“å…¥apiå¯†é’¥", type='password')
    sure1 = st.button("ç¡®å®šå¯†é’¥")
    if sure1 and api_key:
        st.session_state["api_key"] = api_key
        st.info("å¯†é’¥æ›´æ–°æˆåŠŸğŸ˜")
def set_memory(memory):
        if memory == "ConversationBufferWindowMemory":
            st.session_state["memory"] = ConversationBufferWindowMemory(return_messages=True, memory_key='chat_history',
                                                                        k=7)
        elif memory == "ConversationSummaryMemory":
            st.session_state["memory"] = ConversationSummaryMemory(return_messages=True, memory_key='chat_history',
                                                                   llm=st.session_state["model"])
        elif memory == "ConversationSummaryBufferMemory":
            st.session_state["memory"] = ConversationSummaryBufferMemory(llm=st.session_state["model"],
                                                                         max_token_limit=3000, memory_key='chat_history',
                                                                         return_messages=True)
        else:
            st.session_state["memory"] = ConversationBufferMemory(return_messages=True, memory_key='chat_history')
def set_model_param():
    st.session_state["model"]=model
    set_memory(memory)
    st.session_state["temperature"]=temperature



st.markdown("<br><br>", unsafe_allow_html=True)

if "messages" not in st.session_state:
    st.session_state["messages"] = [{"role": "AI", "content": "ä½ å¥½ï¼Œæˆ‘æ˜¯å°å¦²å·±ï¼Œæœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©ä¸»äººçš„å‘€ï¼Ÿ"}]


for message in st.session_state["messages"]:
    st.chat_message(message["role"]).write(message["content"])

prompt = st.chat_input()
if  "memory" not in st.session_state:
    st.info("è¯·ç¡®å®šå‚æ•°")
if prompt:
    if "api_key" not in st.session_state:
        st.info("è¯·å…ˆæä¾›å¯†ç å°å¦²å·±æ‰èƒ½å·¥ä½œå“Ÿ")
        st.stop()
    st.session_state["messages"].append({"role": "human", "content": prompt})
    st.chat_message("human").write(prompt)
    with st.spinner("è®©æˆ‘æƒ³æƒ³æ˜‚ğŸ¤”"):
        response = get_chat_response(st.session_state["model"], prompt, st.session_state["memory"],
                                     st.session_state["api_key"],
                                     st.session_state["temperature"])
        message = {'role': 'AI', 'content': response}
        st.session_state["messages"].append(message)
        st.chat_message("ai").write(message['content'])

if "messages_list" not in st.session_state:
    st.session_state["messages_list"] = []
if "conditions" not in st.session_state:
    st.session_state["conditions"] = []
if "chat_number" not in st.session_state:
    st.session_state["chat_number"] = 0


def save_dialog():  # ä¿å­˜å¯¹è¯
    condition = [st.session_state["model"], st.session_state["temperature"], st.session_state["memory"]]
    st.session_state["conditions"].append(condition)
    st.session_state["messages_list"].append(st.session_state["messages"])
    st.session_state["memory"]=ConversationBufferMemory(return_messages=True, memory_key='chat_history')
    st.session_state["messages"]=st.session_state["messages"] = [{"role": "AI", "content": "ä½ å¥½ï¼Œæˆ‘æ˜¯å°å¦²å·±ï¼Œæœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©ä¸»äººçš„å‘€ï¼Ÿ"}]
    st.session_state["model"]="gpt-4o"
    st.session_state["temperature"]=1


def load_dialog(a):  # åŠ è½½å¯¹è¯
    st.session_state["model"] = st.session_state["conditions"][a][0]
    st.session_state["temperature"] = st.session_state["conditions"][a][1]
    st.session_state["memory"] = st.session_state["conditions"][a][2]
    st.session_state["messages"] = st.session_state["messages_list"][a]


with st.sidebar:
    set_api_key()
    tab1, tab2, tab3 = st.tabs(['model', 'memory', 'temperature'])
    with tab1:
        model = st.selectbox("è¯·é€‰æ‹©ä½ æƒ³ä½¿ç”¨çš„æ¨¡å‹",
                             ["gpt-4o", "gpt-4o-mini", "gpt-4-turbo", "gpt-4", "gpt-4-32k"],
                             index=0)
    with tab2:
        memory = st.selectbox("è¯·é€‰æ‹©ä½ æƒ³ä½¿ç”¨çš„è®°å¿†",
                              ["ConversationBufferMemory", "ConversationBufferWindowMemory",
                               "ConversationSummaryMemory",
                               "ConversationSummaryBufferMemory"], index=0)
    with tab3:
        temperature = st.slider("è¯·é€‰æ‹©ç”Ÿæˆå†…å®¹çš„å¤šæ ·æ€§", min_value=0.10, max_value=1.25, value=1.00,
                                step=0.05)
    if st.button("ç¡®å®šå‚æ•°"):
        set_model_param()
        st.info("æ›´æ”¹æˆåŠŸ")
    st.divider()
    if st.button("åˆ›å»ºæ–°å¯¹è¯"):
        with st.spinner("æ­£åœ¨ä¿å­˜ğŸ³"):
            save_dialog()
        st.session_state["chat_number"] += 1
    if (st.session_state["chat_number"]) != 0:
        for a in range(st.session_state["chat_number"] - 1):
            if st.button(f"å¯¹è¯{a + 1}"):
                load_dialog(a)

with st.expander("ä½¿ç”¨è¯´æ˜"):
    '''
    1.ç¬¬ä¸€æ¬¡å¯¹è¯éœ€è¦æ‰‹åŠ¨é€‰æ‹©å‚æ•°ï¼Œä¹‹ååˆ›å»ºæ–°å¯¹è¯åˆ™é»˜è®¤å‚æ•°ï¼ˆgpt-4o,ConversationBufferMemory,1ï¼‰,å»ºè®®åœ¨å¼€å§‹ä¸€æ®µå¯¹è¯å‰å°±å°†å‚æ•°è®¾ç½®å¥½ï¼Œä¸”ä¸­é€”ä¸å†æ”¹å‚æ•°ï¼Œ
      å¦åˆ™å†å²å¯¹è¯ä¼šä¸¢å¤±
    
    2.modelè¯´æ˜ï¼š
    
        gpt-4-32K>gpt-4>gpt-4o>gpt-4o-mini{ä»·æ ¼åˆ†åˆ«æ¯ä¸€ç™¾ä¸‡token(å¤§æ¦‚70ä¸‡å­—,åŒ…æ‹¬è¾“å…¥,è¾“å‡º)ä¸º60ï¼Œ30ï¼Œ2.5ï¼Œ0.15[å•ä½:ç¾å…ƒ](å®˜ç½‘å®šä»·)}
        
    3.è®°å¿†è¯´æ˜ï¼ˆä¹Ÿå¯è¡¡é‡ä»·æ ¼ï¼‰ï¼š
    
        ConversationBufferMemoryï¼šå°†ä½ çš„å†å²å¯¹è¯å…¨éƒ¨ä¼ å…¥ï¼ˆç®—ä½œè¾“å…¥ï¼‰
        
        ConversationBufferWindowMemoryï¼šåªå°†7è½®å†…çš„å¯¹è¯ä¼ å…¥
        
        ConversationSummaryMemoryï¼šå°†å†å²å¯¹è¯æ€»ç»“å†ä¼ å…¥ï¼ˆæ€»ç»“ä¼šè‡ªåŠ¨è°ƒç”¨æ¨¡å‹ä¼šæ¶ˆè€—tokenï¼‰
        
        ConversationSummaryBufferMemory:å°†å†å²å¯¹è¯æ€»ç»“ä¸”åªä¿ç•™3000tokençš„ä¿¡æ¯ï¼ˆæ¯”è¾ƒé¸¡è‚‹ï¼‰
        
        å†è¯´æ˜ï¼šæ— è®ºé€‰æ‹©å“ªç§ï¼Œéƒ½æœ‰ä¸€ä¸ªä¸Šé™ï¼Œè¿™ä¸ªä¸Šé™åŒ…æ‹¬è¾“å…¥è¾“å‡ºå’Œå†å²å¯¹è¯ï¼Œè¶…è¿‡åˆ™å†å²å¯¹è¯ä¿å­˜ä¸å…¨æˆ–è€…å›ç­”ä¼šå›ä¸å…¨ï¼ˆè¢«æˆªæ–­ï¼‰ï¼ˆgpt-4-32kä¸­çš„32kå°±è¡¨ç¤ºtokenä¸Šé™ï¼‰
        
    4.AIå¹¶ä¸æ˜¯æ— æ‰€ä¸èƒ½ï¼Œä½ çš„è¦æ±‚è¶Šæ˜ç¡®ï¼Œå®ƒçš„å›ç­”å¯èƒ½è¶Šä»¤äººæ»¡æ„ã€‚
    
      å¥½çš„æç¤º:
      
        1.æŠŠæŒ‡ä»¤æ”¾åœ¨æç¤ºçš„å¼€å¤´ï¼Œå¹¶ä¸”ç”¨###æˆ–"""æ¥åˆ†éš”æŒ‡ä»¤å’Œä¸Šä¸‹æ–‡

        2.å°½å¯èƒ½å¯¹ä¸Šä¸‹æ–‡å’Œè¾“å‡ºçš„é•¿åº¦ï¼Œæ ¼å¼ï¼Œé£æ ¼ç­‰ç»™å‡ºå…·ä½“ï¼Œæè¿°æ€§ï¼Œè¯¦ç»†çš„è¦æ±‚
                
        3.é€šè¿‡ä¸€äº›ä¾‹å­æ¥é˜æ˜æƒ³è¦çš„è¾“å‡ºæ ¼å¼
                
        4.å…ˆä»é›¶æ ·æœ¬æç¤ºå¼€å§‹ï¼Œæ•ˆæœä¸å¥½ï¼Œåˆ™ç”¨ç®€å•æ ·æœ¬(å°æ ·æœ¬)æç¤º
                
        5.å‡å°‘ç©ºæ´å’Œä¸ä¸¥è°¨çš„æè¿°
                
        6.å°½é‡å‘ŠçŸ¥å…¶åº”è¯¥åšä»€ä¹ˆï¼Œè€Œä¸æ˜¯ä¸åº”è¯¥åšä»€ä¹ˆ
    '''
